{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU9BFaGfbF_B",
        "outputId": "58a7265f-2a4f-4ffe-d411-b8748591f267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWkFIAmSskvR"
      },
      "source": [
        "# --- 1. Data Loading and Preprocessing ---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Attention\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import joblib\n",
        "import os"
      ],
      "metadata": {
        "id": "VWTx2XcrvLBU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX1x9Ub0stXI",
        "outputId": "2c4da2b7-7fee-414d-f0b2-fd7fc3d2bd15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4ecf3b5ab93b>:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df.fillna(method='ffill', inplace=True)\n",
            "<ipython-input-3-4ecf3b5ab93b>:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df.fillna(method='bfill', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/FYPDataset/merged_cloud_metrics.csv')\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "# Feature engineering\n",
        "df['hour'] = df['timestamp'].dt.hour\n",
        "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "df['is_weekend'] = df['timestamp'].dt.dayofweek.isin([5, 6]).astype(int)\n",
        "df['month'] = df['timestamp'].dt.month\n",
        "\n",
        "metrics = ['EC2_CPUUtilization', 'EC2_MemoryUtilization', 'RDS_CPUUtilization', 'ECS_CPUUtilization']\n",
        "for metric in metrics:\n",
        "    df[f'{metric}_rolling_mean_6h'] = df[metric].rolling(window=6).mean()\n",
        "    df[f'{metric}_rolling_std_6h'] = df[metric].rolling(window=6).std()\n",
        "\n",
        "df['EC2_CPU_Memory_Ratio'] = df['EC2_CPUUtilization'] / df['EC2_MemoryUtilization'].replace(0, 1e-6)\n",
        "df['RDS_Connections_Per_CPU'] = df['RDS_DatabaseConnections'] / df['RDS_CPUUtilization'].replace(0, 1e-6)\n",
        "\n",
        "df.fillna(method='ffill', inplace=True)\n",
        "df.fillna(method='bfill', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqvQprHvsv08"
      },
      "source": [
        "# --- 2. Feature and Target Preparation ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1pWTBG7Ds0KB"
      },
      "outputs": [],
      "source": [
        "# Define target and feature columns\n",
        "target_cols = ['EC2_CPUUtilization', 'EC2_MemoryUtilization', 'RDS_CPUUtilization',\n",
        "               'RDS_FreeableMemory', 'ECS_CPUUtilization', 'ECS_MemoryUtilization']\n",
        "feature_cols = [col for col in df.columns if col not in ['timestamp'] + target_cols]\n",
        "\n",
        "# Apply log transformation to target variables (adding small constant to handle zeros)\n",
        "EPSILON = 1e-6\n",
        "for col in target_cols:\n",
        "    df[col] = np.log1p(df[col] + EPSILON)\n",
        "\n",
        "X = df[feature_cols].values\n",
        "y = df[target_cols].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yax1SMhcs3xy"
      },
      "source": [
        "# --- 3. Data Scaling and Sequence Creation ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Z7DQD-YNtFMb"
      },
      "outputs": [],
      "source": [
        "# Data scaling\n",
        "scalers = {}\n",
        "scalers['features'] = MinMaxScaler()\n",
        "scalers['targets'] = MinMaxScaler()\n",
        "\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "X_train_scaled = scalers['features'].fit_transform(X_train)\n",
        "X_test_scaled = scalers['features'].transform(X_test)\n",
        "y_train_scaled = scalers['targets'].fit_transform(y_train)\n",
        "y_test_scaled = scalers['targets'].transform(y_test)\n",
        "\n",
        "# Sequence creation\n",
        "sequence_length = 24\n",
        "prediction_horizon = 1\n",
        "\n",
        "def create_sequences(X, y, seq_length, pred_horizon):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - seq_length - pred_horizon + 1):\n",
        "        X_seq.append(X[i:(i + seq_length)])\n",
        "        y_seq.append(y[i + seq_length:i + seq_length + pred_horizon])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, sequence_length, prediction_horizon)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, sequence_length, prediction_horizon)\n",
        "\n",
        "# Custom MAPE metric that handles small values\n",
        "class CustomMAPE(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='custom_mape', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.total = self.add_weight(name='total', initializer='zeros')\n",
        "        self.count = self.add_weight(name='count', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        epsilon = tf.constant(1e-6, dtype=tf.float32)\n",
        "        absolute_percentage_errors = tf.abs((y_true - y_pred) / (y_true + epsilon))\n",
        "        mape = tf.reduce_mean(absolute_percentage_errors) * 100\n",
        "\n",
        "        self.total.assign_add(mape)\n",
        "        self.count.assign_add(1.0)\n",
        "\n",
        "    def result(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.total.assign(0.0)\n",
        "        self.count.assign(0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQPyv8eptI4x"
      },
      "source": [
        "# --- 4. Model Building and Training ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eE8xsqTtMyW",
        "outputId": "40384d88-c0e4-484b-c777-c0bf18191647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 8ms/step - custom_mape: 229.8238 - loss: 0.0386 - mae: 0.1513 - val_custom_mape: 96.8217 - val_loss: 0.0412 - val_mae: 0.1712\n",
            "Epoch 2/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 8ms/step - custom_mape: 188.6579 - loss: 0.0368 - mae: 0.1483 - val_custom_mape: 98.2802 - val_loss: 0.0402 - val_mae: 0.1681\n",
            "Epoch 3/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 8ms/step - custom_mape: 211.4270 - loss: 0.0368 - mae: 0.1484 - val_custom_mape: 99.1590 - val_loss: 0.0395 - val_mae: 0.1652\n",
            "Epoch 4/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 8ms/step - custom_mape: 197.0334 - loss: 0.0368 - mae: 0.1482 - val_custom_mape: 98.7999 - val_loss: 0.0390 - val_mae: 0.1632\n",
            "Epoch 5/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 8ms/step - custom_mape: 222.5396 - loss: 0.0368 - mae: 0.1483 - val_custom_mape: 99.9821 - val_loss: 0.0380 - val_mae: 0.1589\n",
            "Epoch 6/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 8ms/step - custom_mape: 249.5216 - loss: 0.0368 - mae: 0.1482 - val_custom_mape: 100.1678 - val_loss: 0.0380 - val_mae: 0.1585\n",
            "Epoch 7/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 8ms/step - custom_mape: 212.1380 - loss: 0.0368 - mae: 0.1483 - val_custom_mape: 99.5924 - val_loss: 0.0386 - val_mae: 0.1619\n",
            "Epoch 8/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8ms/step - custom_mape: 241.2206 - loss: 0.0368 - mae: 0.1483 - val_custom_mape: 100.4766 - val_loss: 0.0374 - val_mae: 0.1558\n",
            "Epoch 9/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8ms/step - custom_mape: 154.8780 - loss: 0.0368 - mae: 0.1483 - val_custom_mape: 101.0644 - val_loss: 0.0374 - val_mae: 0.1553\n",
            "Epoch 10/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 8ms/step - custom_mape: 259.4957 - loss: 0.0368 - mae: 0.1483 - val_custom_mape: 101.6595 - val_loss: 0.0371 - val_mae: 0.1532\n",
            "Epoch 11/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 8ms/step - custom_mape: 245.4471 - loss: 0.0368 - mae: 0.1482 - val_custom_mape: 102.1268 - val_loss: 0.0369 - val_mae: 0.1521\n",
            "Epoch 12/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 8ms/step - custom_mape: 281.7824 - loss: 0.0368 - mae: 0.1482 - val_custom_mape: 102.0762 - val_loss: 0.0368 - val_mae: 0.1507\n",
            "Epoch 13/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8ms/step - custom_mape: 244.3252 - loss: 0.0368 - mae: 0.1482 - val_custom_mape: 102.5709 - val_loss: 0.0368 - val_mae: 0.1509\n",
            "Epoch 14/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8ms/step - custom_mape: 260.0961 - loss: 0.0368 - mae: 0.1482 - val_custom_mape: 102.0696 - val_loss: 0.0368 - val_mae: 0.1513\n",
            "Epoch 15/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8ms/step - custom_mape: 209.4248 - loss: 0.0368 - mae: 0.1483 - val_custom_mape: 103.5353 - val_loss: 0.0367 - val_mae: 0.1478\n",
            "Epoch 16/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8ms/step - custom_mape: 179.3914 - loss: 0.0368 - mae: 0.1484 - val_custom_mape: 103.5575 - val_loss: 0.0367 - val_mae: 0.1478\n",
            "Epoch 17/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 8ms/step - custom_mape: 138.9038 - loss: 0.0368 - mae: 0.1483 - val_custom_mape: 103.0224 - val_loss: 0.0367 - val_mae: 0.1479\n",
            "Epoch 18/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8ms/step - custom_mape: 268.4898 - loss: 0.0368 - mae: 0.1483 - val_custom_mape: 103.2145 - val_loss: 0.0367 - val_mae: 0.1480\n",
            "Epoch 19/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8ms/step - custom_mape: 193.3637 - loss: 0.0368 - mae: 0.1482 - val_custom_mape: 103.6544 - val_loss: 0.0367 - val_mae: 0.1479\n",
            "Epoch 20/50\n",
            "\u001b[1m34790/34790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 8ms/step - custom_mape: 319.6624 - loss: 0.0368 - mae: 0.1481 - val_custom_mape: 103.1778 - val_loss: 0.0367 - val_mae: 0.1481\n"
          ]
        }
      ],
      "source": [
        "input_shape = (sequence_length, len(feature_cols))\n",
        "num_targets = len(target_cols)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_targets)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='mse',\n",
        "             metrics=['mae', CustomMAPE()])\n",
        "\n",
        "# Training with callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "]\n",
        "\n",
        "# Model training\n",
        "history = model.fit(\n",
        "    X_train_seq, y_train_seq,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hwRi2G2tTZe"
      },
      "source": [
        "# --- 5. Model Evaluation and Saving ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "nah2P4eBtXMP",
        "outputId": "6adc2d8b-2773-4e98-c998-6e3afeeeb6d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10872/10872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with dim 3. None expected <= 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-29424abdcc47>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Make predictions and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mevaluate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Save model and scalers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-29424abdcc47>\u001b[0m in \u001b[0;36mevaluate_predictions\u001b[0;34m(y_true, y_pred, target_cols)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my_true_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my_pred_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         X = check_array(\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1099\u001b[0m             )\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
          ]
        }
      ],
      "source": [
        "# Evaluation function\n",
        "def evaluate_predictions(y_true, y_pred, target_cols):\n",
        "    y_true_orig = np.expm1(scalers['targets'].inverse_transform(y_true))\n",
        "    y_pred_orig = np.expm1(scalers['targets'].inverse_transform(y_pred))\n",
        "\n",
        "    for i, col in enumerate(target_cols):\n",
        "        mae = np.mean(np.abs(y_true_orig[:, i] - y_pred_orig[:, i]))\n",
        "        mape = np.mean(np.abs((y_true_orig[:, i] - y_pred_orig[:, i]) / (y_true_orig[:, i] + EPSILON))) * 100\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(f\"MAE: {mae:.4f}\")\n",
        "        print(f\"MAPE: {mape:.4f}%\")\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = model.predict(X_test_seq)\n",
        "evaluate_predictions(y_test_seq, y_pred, target_cols)\n",
        "\n",
        "# Save model and scalers\n",
        "os.makedirs('cloud_metrics_lstm_multi_output', exist_ok=True)\n",
        "save_model(model, '/content/drive/MyDrive/FYPDataset/cloud_metrics_lstm_multi_output_model.keras')\n",
        "np.save('/content/drive/MyDrive/FYPDataset/cloud_metrics_lstm_multi_output_features.npy', feature_cols)\n",
        "joblib.dump(scalers['features'], '/content/drive/MyDrive/FYPDataset/cloud_metrics_lstm_multi_output_features_scaler.joblib')\n",
        "joblib.dump(scalers['targets'], '/content/drive/MyDrive/FYPDataset/cloud_metrics_lstm_multi_output_targets_scaler.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni-GXbqrtZdT"
      },
      "source": [
        "Test Accuracy and Plot Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxWNOsOPMv29"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "# Load the saved model and scalers\n",
        "loaded_model = load_model('/content/drive/MyDrive/FYPDataset/cloud_metrics_lstm_multi_output_model.keras')\n",
        "loaded_features = np.load('/content/drive/MyDrive/FYPDataset/cloud_metrics_lstm_multi_output_features.npy', allow_pickle=True)\n",
        "loaded_feature_scaler = joblib.load('/content/drive/MyDrive/FYPDataset/cloud_metrics_lstm_multi_output_features_scaler.joblib')\n",
        "loaded_target_scaler = joblib.load('/content/drive/MyDrive/FYPDataset/cloud_metrics_lstm_multi_output_targets_scaler.joblib')\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_scaled = loaded_model.predict(X_test_seq)\n",
        "y_pred = loaded_target_scaler.inverse_transform(y_pred_scaled)\n",
        "y_actual = loaded_target_scaler.inverse_transform(y_test_seq)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_actual, y_pred)\n",
        "mape = mean_absolute_percentage_error(y_actual, y_pred)\n",
        "r2 = r2_score(y_actual, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\n",
        "print(f\"R-squared (R2): {r2}\")\n",
        "\n",
        "# Plot predictions vs actual for each target variable\n",
        "target_cols = ['EC2_CPUUtilization', 'EC2_MemoryUtilization', 'RDS_CPUUtilization', 'RDS_FreeableMemory', 'ECS_CPUUtilization', 'ECS_MemoryUtilization']\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(target_cols):\n",
        "    plt.subplot(3, 2, i + 1)\n",
        "    plt.plot(y_actual[:, i], label='Actual', color='blue')\n",
        "    plt.plot(y_pred[:, i], label='Predicted', color='red', linestyle='--')\n",
        "    plt.title(f'{col} - Actual vs Predicted')\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.ylabel(col)\n",
        "    plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G84dF8LJMCXU"
      },
      "source": [
        "Visualize actual vs prediction plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import smtplib\n",
        "\n",
        "def send_email():\n",
        "    sender = \"hwimalasooriya@gmail.com\"\n",
        "    receiver = \"hasitha.20210424@iit.ac.lk\"\n",
        "    password = \"uklf urne obbw irdf\"  # Use an App Password for security\n",
        "\n",
        "    subject = \"Training Complete!\"\n",
        "    body = \"Your LSTM model training in Colab has finished.\"\n",
        "\n",
        "    message = f\"Subject: {subject}\\n\\n{body}\"\n",
        "\n",
        "    with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
        "        server.login(sender, password)\n",
        "        server.sendmail(sender, receiver, message)\n",
        "\n",
        "send_email()\n"
      ],
      "metadata": {
        "id": "Za1yuxbT0woZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}