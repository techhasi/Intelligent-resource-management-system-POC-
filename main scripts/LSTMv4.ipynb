{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **LSTM for Cloud Resource Metrics Forecasting**\n",
        "\n",
        "**The model is designed to forecast key AWS resource metrics (EC2, RDS, and ECS CPU utilization) by leveraging historical cloud monitoring data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Mount google drive (If needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive (if using Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Feature engineering\n",
        "\n",
        "    * Extracts time-based features such as the hour of day and day of week.\n",
        "    * Creates utilization ratios (e.g., EC2_CPU/MEM ratio).\n",
        "    * Computes rolling means to smooth out fluctuations.\n",
        "    * Creates lag features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def create_lag_features(df, feature_cols, lag=3):\n",
        "    for col in feature_cols:\n",
        "        for i in range(1, lag + 1):\n",
        "            df[f\"{col}_lag{i}\"] = df[col].shift(i)\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "def add_engineered_features(df, service):\n",
        "    df = df.copy()\n",
        "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
        "    df = df[~df.index.isna()]\n",
        "\n",
        "    # Time-based features\n",
        "    df.loc[:, 'hour'] = df.index.hour\n",
        "    df.loc[:, 'day_of_week'] = df.index.dayofweek\n",
        "\n",
        "    if service == 'EC2':\n",
        "        df.loc[:, 'EC2_CPU_Memory_Ratio'] = np.clip(df['EC2_CPUUtilization'] / (df['EC2_MemoryUtilization'] + 1e-5), 0, 100)\n",
        "        df.loc[:, 'EC2_CPU_rolling_mean'] = df['EC2_CPUUtilization'].rolling(window=5).mean()\n",
        "    elif service == 'RDS':\n",
        "        df.loc[:, 'RDS_Connections_Per_CPU'] = np.clip(df['RDS_DatabaseConnections'] / (df['RDS_CPUUtilization'] + 1e-5), 0, 100)\n",
        "        df.loc[:, 'RDS_CPU_rolling_mean'] = df['RDS_CPUUtilization'].rolling(window=5).mean()\n",
        "    elif service == 'ECS':\n",
        "        df.loc[:, 'ECS_CPU_Memory_Ratio'] = np.clip(df['ECS_CPUUtilization'] / (df['ECS_MemoryUtilization'] + 1e-5), 0, 100)\n",
        "        df.loc[:, 'ECS_Task_Rolling_Mean'] = df['ECS_RunningTaskCount'].rolling(window=5).mean()\n",
        "\n",
        "    # Drop rows with NaN values after rolling calculations\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, data, features, target_col, sequence_length=10):\n",
        "        self.features = data[features].values\n",
        "        self.targets = data[target_col].values\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features) - self.sequence_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx:idx+self.sequence_length]\n",
        "        y = self.targets[idx+self.sequence_length]\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. LSTM Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=256, num_layers=3, dropout=0.35):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out[:, -1, :])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Training the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=50, learning_rate=0.0005, early_stop_patience=5, early_stop_start=15):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    # Scheduler with step size of 5 for more aggressive decay\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
        "    \n",
        "    model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch).squeeze()\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        \n",
        "        val_loss = evaluate_model(model, val_loader)\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
        "        \n",
        "        # Early stopping check starting from early_stop_start epoch\n",
        "        if epoch+1 >= early_stop_start:\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience = 0\n",
        "            else:\n",
        "                patience += 1\n",
        "            if patience >= early_stop_patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Evaluate models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    criterion = nn.MSELoss()\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch).squeeze()\n",
        "            total_loss += criterion(y_pred, y_batch).item()\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "def predict_and_evaluate(model, test_loader, target_scaler, target_feature):\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_pred = model(X_batch).cpu().numpy()\n",
        "            predictions.extend(y_pred)\n",
        "            actuals.extend(y_batch.numpy())\n",
        "    predictions = np.array(predictions).reshape(-1, 1)\n",
        "    actuals = np.array(actuals).reshape(-1, 1)\n",
        "    predictions = target_scaler.inverse_transform(predictions)\n",
        "    actuals = target_scaler.inverse_transform(actuals)\n",
        "    \n",
        "    mae = mean_absolute_error(actuals, predictions)\n",
        "    mse = mean_squared_error(actuals, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(f\"\\nEvaluation for {target_feature}: MAE={mae:.4f}, MSE={mse:.4f}, RMSE={rmse:.4f}\")\n",
        "    \n",
        "    # Plot prediction vs actual\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(actuals, label='Actual', alpha=0.7)\n",
        "    plt.plot(predictions, label='Predicted', alpha=0.7)\n",
        "    plt.title(f\"Prediction vs Actual for {target_feature}\")\n",
        "    plt.xlabel(\"Sample\")\n",
        "    plt.ylabel(target_feature)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    results = pd.DataFrame({\"Actual\": actuals.flatten(), \"Predicted\": predictions.flatten()})\n",
        "    results.to_csv(f\"{target_feature}_predictions.csv\", index=False)\n",
        "    return mae, mse, rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. Main process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_info = {\n",
        "    'EC2': {\n",
        "        'path': \"reduced_ec2_data.csv\",\n",
        "        'features': ['EC2_CPUUtilization', 'EC2_MemoryUtilization', 'EC2_DiskWriteOps', 'EC2_NetworkIn']\n",
        "    },\n",
        "    'RDS': {\n",
        "        'path': \"reduced_rds_data.csv\",\n",
        "        'features': ['RDS_CPUUtilization', 'RDS_FreeableMemory', 'RDS_DatabaseConnections', 'RDS_WriteIOPS']\n",
        "    },\n",
        "    'ECS': {\n",
        "        'path': \"reduced_ecs_data.csv\",\n",
        "        'features': ['ECS_CPUUtilization', 'ECS_MemoryUtilization', 'ECS_RunningTaskCount']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Additional engineered features for each service\n",
        "engineered_features = {\n",
        "    'EC2': ['hour', 'day_of_week', 'EC2_CPU_Memory_Ratio', 'EC2_CPU_rolling_mean'],\n",
        "    'RDS': ['hour', 'day_of_week', 'RDS_Connections_Per_CPU', 'RDS_CPU_rolling_mean'],\n",
        "    'ECS': ['hour', 'day_of_week', 'ECS_CPU_Memory_Ratio', 'ECS_Task_Rolling_Mean']\n",
        "}\n",
        "\n",
        "# Dictionary to store target scalers (one per service)\n",
        "target_scalers = {}\n",
        "\n",
        "sequence_length = 10\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "for resource, info in dataset_info.items():\n",
        "    print(f\"\\n=== Processing {resource} Dataset ===\")\n",
        "    df = pd.read_csv(info['path'], index_col=0)\n",
        "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
        "    \n",
        "    # Add engineered features\n",
        "    df = add_engineered_features(df, resource)\n",
        "    \n",
        "    # Initial feature list: original + engineered\n",
        "    base_features = info['features'] + engineered_features[resource]\n",
        "    \n",
        "    # Create lag features and update feature list\n",
        "    df = create_lag_features(df, base_features, lag=3)\n",
        "    features = [col for col in df.columns if col in base_features or any(col.startswith(f\"{feat}_lag\") for feat in base_features)]\n",
        "    target_feature = info['features'][0]\n",
        "\n",
        "    print(f\"{resource} - Target ({target_feature}) mean: {df[target_feature].mean():.4f}, std: {df[target_feature].std():.4f}\")\n",
        "    print(f\"{resource} - Total features: {len(features)}\")  # Debug: Confirm feature count\n",
        "    \n",
        "    # Scale features and target\n",
        "    feature_scaler = StandardScaler()\n",
        "    target_scaler = StandardScaler()\n",
        "    df[features] = feature_scaler.fit_transform(df[features])\n",
        "    df[target_feature] = target_scaler.fit_transform(df[[target_feature]])\n",
        "    target_scalers[resource] = target_scaler\n",
        "\n",
        "    # Create dataset and split\n",
        "    dataset = TimeSeriesDataset(df, features, target_feature, sequence_length)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    # Train and save model\n",
        "    model = LSTMModel(input_size=len(features))\n",
        "    print(f\"Training {resource} model with input_size={len(features)}...\")\n",
        "    train_model(model, train_loader, val_loader, epochs=epochs, learning_rate=0.0005)\n",
        "    \n",
        "    model_path = f\"{resource}_lstm_model.pth\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Saved {resource} model to {model_path}\")\n",
        "    \n",
        "    # Evaluate\n",
        "    print(f\"Evaluating {resource} model...\")\n",
        "    predict_and_evaluate(model, val_loader, target_scalers[resource], target_feature)\n",
        "\n",
        "print(\"\\nAll models trained, evaluated, and saved!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "model_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
