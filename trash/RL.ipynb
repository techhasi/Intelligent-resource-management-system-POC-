{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/500, Total Reward: -7.55\n",
      "Episode 2/500, Total Reward: 0.68\n",
      "Episode 3/500, Total Reward: -5.28\n",
      "Episode 4/500, Total Reward: -11.52\n",
      "Episode 5/500, Total Reward: -9.99\n",
      "Episode 6/500, Total Reward: 2.15\n",
      "Episode 7/500, Total Reward: 1.08\n",
      "Episode 8/500, Total Reward: -10.65\n",
      "Episode 9/500, Total Reward: 0.75\n",
      "Episode 10/500, Total Reward: -2.30\n",
      "Episode 11/500, Total Reward: 5.30\n",
      "Episode 12/500, Total Reward: -5.92\n",
      "Episode 13/500, Total Reward: -3.04\n",
      "Episode 14/500, Total Reward: -4.19\n",
      "Episode 15/500, Total Reward: 6.88\n",
      "Episode 16/500, Total Reward: -7.13\n",
      "Episode 17/500, Total Reward: -1.49\n",
      "Episode 18/500, Total Reward: 1.69\n",
      "Episode 19/500, Total Reward: -3.39\n",
      "Episode 20/500, Total Reward: -3.88\n",
      "Episode 21/500, Total Reward: -6.12\n",
      "Episode 22/500, Total Reward: -0.12\n",
      "Episode 23/500, Total Reward: -0.82\n",
      "Episode 24/500, Total Reward: -1.80\n",
      "Episode 25/500, Total Reward: -8.95\n",
      "Episode 26/500, Total Reward: -1.54\n",
      "Episode 27/500, Total Reward: -1.15\n",
      "Episode 28/500, Total Reward: -1.08\n",
      "Episode 29/500, Total Reward: 3.28\n",
      "Episode 30/500, Total Reward: -5.86\n",
      "Episode 31/500, Total Reward: 4.73\n",
      "Episode 32/500, Total Reward: -2.05\n",
      "Episode 33/500, Total Reward: -4.01\n",
      "Episode 34/500, Total Reward: -3.88\n",
      "Episode 35/500, Total Reward: 4.46\n",
      "Episode 36/500, Total Reward: 0.22\n",
      "Episode 37/500, Total Reward: 3.08\n",
      "Episode 38/500, Total Reward: 2.01\n",
      "Episode 39/500, Total Reward: -2.42\n",
      "Episode 40/500, Total Reward: 4.39\n",
      "Episode 41/500, Total Reward: 2.71\n",
      "Episode 42/500, Total Reward: 2.63\n",
      "Episode 43/500, Total Reward: 0.02\n",
      "Episode 44/500, Total Reward: 7.15\n",
      "Episode 45/500, Total Reward: -12.21\n",
      "Episode 46/500, Total Reward: 1.59\n",
      "Episode 47/500, Total Reward: 0.80\n",
      "Episode 48/500, Total Reward: -0.82\n",
      "Episode 49/500, Total Reward: 1.79\n",
      "Episode 50/500, Total Reward: -5.91\n",
      "Episode 51/500, Total Reward: -3.84\n",
      "Episode 52/500, Total Reward: -3.64\n",
      "Episode 53/500, Total Reward: 2.94\n",
      "Episode 54/500, Total Reward: -0.78\n",
      "Episode 55/500, Total Reward: 5.88\n",
      "Episode 56/500, Total Reward: 4.64\n",
      "Episode 57/500, Total Reward: -3.40\n",
      "Episode 58/500, Total Reward: 1.60\n",
      "Episode 59/500, Total Reward: -7.61\n",
      "Episode 60/500, Total Reward: -1.66\n",
      "Episode 61/500, Total Reward: 0.78\n",
      "Episode 62/500, Total Reward: 2.93\n",
      "Episode 63/500, Total Reward: 11.82\n",
      "Episode 64/500, Total Reward: -0.18\n",
      "Episode 65/500, Total Reward: 7.08\n",
      "Episode 66/500, Total Reward: -2.66\n",
      "Episode 67/500, Total Reward: 9.78\n",
      "Episode 68/500, Total Reward: 7.38\n",
      "Episode 69/500, Total Reward: -1.63\n",
      "Episode 70/500, Total Reward: 8.70\n",
      "Episode 71/500, Total Reward: 6.47\n",
      "Episode 72/500, Total Reward: -3.00\n",
      "Episode 73/500, Total Reward: 1.19\n",
      "Episode 74/500, Total Reward: -1.54\n",
      "Episode 75/500, Total Reward: 8.79\n",
      "Episode 76/500, Total Reward: 1.97\n",
      "Episode 77/500, Total Reward: 2.89\n",
      "Episode 78/500, Total Reward: -6.36\n",
      "Episode 79/500, Total Reward: -0.15\n",
      "Episode 80/500, Total Reward: 2.92\n",
      "Episode 81/500, Total Reward: -0.65\n",
      "Episode 82/500, Total Reward: -1.95\n",
      "Episode 83/500, Total Reward: 8.68\n",
      "Episode 84/500, Total Reward: -9.35\n",
      "Episode 85/500, Total Reward: 5.10\n",
      "Episode 86/500, Total Reward: 2.80\n",
      "Episode 87/500, Total Reward: 5.16\n",
      "Episode 88/500, Total Reward: 2.56\n",
      "Episode 89/500, Total Reward: 3.90\n",
      "Episode 90/500, Total Reward: -6.35\n",
      "Episode 91/500, Total Reward: 3.51\n",
      "Episode 92/500, Total Reward: 3.01\n",
      "Episode 93/500, Total Reward: 5.06\n",
      "Episode 94/500, Total Reward: -2.93\n",
      "Episode 95/500, Total Reward: 0.40\n",
      "Episode 96/500, Total Reward: 3.28\n",
      "Episode 97/500, Total Reward: 0.64\n",
      "Episode 98/500, Total Reward: 4.48\n",
      "Episode 99/500, Total Reward: 0.55\n",
      "Episode 100/500, Total Reward: 1.81\n",
      "Episode 101/500, Total Reward: 0.04\n",
      "Episode 102/500, Total Reward: 0.57\n",
      "Episode 103/500, Total Reward: 4.06\n",
      "Episode 104/500, Total Reward: 0.72\n",
      "Episode 105/500, Total Reward: 5.27\n",
      "Episode 106/500, Total Reward: 7.98\n",
      "Episode 107/500, Total Reward: 4.88\n",
      "Episode 108/500, Total Reward: 1.30\n",
      "Episode 109/500, Total Reward: 0.80\n",
      "Episode 110/500, Total Reward: -0.52\n",
      "Episode 111/500, Total Reward: 1.21\n",
      "Episode 112/500, Total Reward: 1.52\n",
      "Episode 113/500, Total Reward: 4.72\n",
      "Episode 114/500, Total Reward: 1.92\n",
      "Episode 115/500, Total Reward: 6.75\n",
      "Episode 116/500, Total Reward: 6.88\n",
      "Episode 117/500, Total Reward: 0.77\n",
      "Episode 118/500, Total Reward: 1.76\n",
      "Episode 119/500, Total Reward: 4.50\n",
      "Episode 120/500, Total Reward: 1.50\n",
      "Episode 121/500, Total Reward: 10.44\n",
      "Episode 122/500, Total Reward: 6.91\n",
      "Episode 123/500, Total Reward: 10.09\n",
      "Episode 124/500, Total Reward: 3.81\n",
      "Episode 125/500, Total Reward: 4.70\n",
      "Episode 126/500, Total Reward: -2.54\n",
      "Episode 127/500, Total Reward: 7.54\n",
      "Episode 128/500, Total Reward: 4.54\n",
      "Episode 129/500, Total Reward: 1.54\n",
      "Episode 130/500, Total Reward: 4.62\n",
      "Episode 131/500, Total Reward: 3.19\n",
      "Episode 132/500, Total Reward: 2.74\n",
      "Episode 133/500, Total Reward: 2.24\n",
      "Episode 134/500, Total Reward: -2.51\n",
      "Episode 135/500, Total Reward: 3.36\n",
      "Episode 136/500, Total Reward: 3.44\n",
      "Episode 137/500, Total Reward: 7.11\n",
      "Episode 138/500, Total Reward: -4.21\n",
      "Episode 139/500, Total Reward: 5.47\n",
      "Episode 140/500, Total Reward: 4.01\n",
      "Episode 141/500, Total Reward: 0.01\n",
      "Episode 142/500, Total Reward: 4.03\n",
      "Episode 143/500, Total Reward: 2.83\n",
      "Episode 144/500, Total Reward: 8.45\n",
      "Episode 145/500, Total Reward: 5.64\n",
      "Episode 146/500, Total Reward: 8.66\n",
      "Episode 147/500, Total Reward: 0.48\n",
      "Episode 148/500, Total Reward: 0.72\n",
      "Episode 149/500, Total Reward: 5.64\n",
      "Episode 150/500, Total Reward: 6.90\n",
      "Episode 151/500, Total Reward: 5.45\n",
      "Episode 152/500, Total Reward: 6.75\n",
      "Episode 153/500, Total Reward: 7.14\n",
      "Episode 154/500, Total Reward: 2.06\n",
      "Episode 155/500, Total Reward: 2.15\n",
      "Episode 156/500, Total Reward: 1.96\n",
      "Episode 157/500, Total Reward: 4.18\n",
      "Episode 158/500, Total Reward: 3.07\n",
      "Episode 159/500, Total Reward: 4.93\n",
      "Episode 160/500, Total Reward: 8.19\n",
      "Episode 161/500, Total Reward: 9.03\n",
      "Episode 162/500, Total Reward: 11.82\n",
      "Episode 163/500, Total Reward: -2.46\n",
      "Episode 164/500, Total Reward: 3.62\n",
      "Episode 165/500, Total Reward: 10.27\n",
      "Episode 166/500, Total Reward: 6.92\n",
      "Episode 167/500, Total Reward: 2.28\n",
      "Episode 168/500, Total Reward: 10.33\n",
      "Episode 169/500, Total Reward: 6.40\n",
      "Episode 170/500, Total Reward: 1.06\n",
      "Episode 171/500, Total Reward: 6.64\n",
      "Episode 172/500, Total Reward: 10.32\n",
      "Episode 173/500, Total Reward: -1.01\n",
      "Episode 174/500, Total Reward: 10.34\n",
      "Episode 175/500, Total Reward: 7.87\n",
      "Episode 176/500, Total Reward: 13.44\n",
      "Episode 177/500, Total Reward: 2.73\n",
      "Episode 178/500, Total Reward: 12.90\n",
      "Episode 179/500, Total Reward: 3.57\n",
      "Episode 180/500, Total Reward: 1.39\n",
      "Episode 181/500, Total Reward: 5.11\n",
      "Episode 182/500, Total Reward: 4.73\n",
      "Episode 183/500, Total Reward: 1.30\n",
      "Episode 184/500, Total Reward: 3.55\n",
      "Episode 185/500, Total Reward: 5.10\n",
      "Episode 186/500, Total Reward: 6.29\n",
      "Episode 187/500, Total Reward: 13.67\n",
      "Episode 188/500, Total Reward: 5.08\n",
      "Episode 189/500, Total Reward: -0.05\n",
      "Episode 190/500, Total Reward: 4.20\n",
      "Episode 191/500, Total Reward: 1.26\n",
      "Episode 192/500, Total Reward: 1.92\n",
      "Episode 193/500, Total Reward: 8.22\n",
      "Episode 194/500, Total Reward: 4.81\n",
      "Episode 195/500, Total Reward: 1.13\n",
      "Episode 196/500, Total Reward: 2.96\n",
      "Episode 197/500, Total Reward: 6.87\n",
      "Episode 198/500, Total Reward: 8.90\n",
      "Episode 199/500, Total Reward: 14.93\n",
      "Episode 200/500, Total Reward: 3.07\n",
      "Episode 201/500, Total Reward: 5.45\n",
      "Episode 202/500, Total Reward: 12.96\n",
      "Episode 203/500, Total Reward: 3.62\n",
      "Episode 204/500, Total Reward: 1.07\n",
      "Episode 205/500, Total Reward: 7.99\n",
      "Episode 206/500, Total Reward: 2.30\n",
      "Episode 207/500, Total Reward: 9.78\n",
      "Episode 208/500, Total Reward: 5.08\n",
      "Episode 209/500, Total Reward: 7.15\n",
      "Episode 210/500, Total Reward: 5.21\n",
      "Episode 211/500, Total Reward: 4.53\n",
      "Episode 212/500, Total Reward: 15.57\n",
      "Episode 213/500, Total Reward: 7.95\n",
      "Episode 214/500, Total Reward: 4.51\n",
      "Episode 215/500, Total Reward: 6.46\n",
      "Episode 216/500, Total Reward: 5.41\n",
      "Episode 217/500, Total Reward: 13.72\n",
      "Episode 218/500, Total Reward: 4.70\n",
      "Episode 219/500, Total Reward: 15.39\n",
      "Episode 220/500, Total Reward: 10.86\n",
      "Episode 221/500, Total Reward: 8.55\n",
      "Episode 222/500, Total Reward: 5.65\n",
      "Episode 223/500, Total Reward: 11.81\n",
      "Episode 224/500, Total Reward: 3.46\n",
      "Episode 225/500, Total Reward: 10.25\n",
      "Episode 226/500, Total Reward: 4.24\n",
      "Episode 227/500, Total Reward: 7.77\n",
      "Episode 228/500, Total Reward: -2.23\n",
      "Episode 229/500, Total Reward: 2.92\n",
      "Episode 230/500, Total Reward: 10.26\n",
      "Episode 231/500, Total Reward: 4.52\n",
      "Episode 232/500, Total Reward: 11.82\n",
      "Episode 233/500, Total Reward: 6.71\n",
      "Episode 234/500, Total Reward: 6.55\n",
      "Episode 235/500, Total Reward: 5.03\n",
      "Episode 236/500, Total Reward: 6.63\n",
      "Episode 237/500, Total Reward: 0.92\n",
      "Episode 238/500, Total Reward: 8.38\n",
      "Episode 239/500, Total Reward: 6.30\n",
      "Episode 240/500, Total Reward: -1.75\n",
      "Episode 241/500, Total Reward: 11.17\n",
      "Episode 242/500, Total Reward: 6.66\n",
      "Episode 243/500, Total Reward: 4.52\n",
      "Episode 244/500, Total Reward: 4.83\n",
      "Episode 245/500, Total Reward: 6.10\n",
      "Episode 246/500, Total Reward: 3.92\n",
      "Episode 247/500, Total Reward: 4.76\n",
      "Episode 248/500, Total Reward: 5.80\n",
      "Episode 249/500, Total Reward: 9.04\n",
      "Episode 250/500, Total Reward: 8.26\n",
      "Episode 251/500, Total Reward: 7.39\n",
      "Episode 252/500, Total Reward: 3.53\n",
      "Episode 253/500, Total Reward: 5.70\n",
      "Episode 254/500, Total Reward: 6.55\n",
      "Episode 255/500, Total Reward: 15.01\n",
      "Episode 256/500, Total Reward: 7.64\n",
      "Episode 257/500, Total Reward: 9.84\n",
      "Episode 258/500, Total Reward: 9.24\n",
      "Episode 259/500, Total Reward: -0.07\n",
      "Episode 260/500, Total Reward: 10.37\n",
      "Episode 261/500, Total Reward: 13.15\n",
      "Episode 262/500, Total Reward: 0.67\n",
      "Episode 263/500, Total Reward: 1.07\n",
      "Episode 264/500, Total Reward: 12.99\n",
      "Episode 265/500, Total Reward: 10.18\n",
      "Episode 266/500, Total Reward: 15.87\n",
      "Episode 267/500, Total Reward: 0.05\n",
      "Episode 268/500, Total Reward: 7.06\n",
      "Episode 269/500, Total Reward: 12.05\n",
      "Episode 270/500, Total Reward: 7.06\n",
      "Episode 271/500, Total Reward: 14.36\n",
      "Episode 272/500, Total Reward: 4.38\n",
      "Episode 273/500, Total Reward: 7.60\n",
      "Episode 274/500, Total Reward: 10.15\n",
      "Episode 275/500, Total Reward: 4.68\n",
      "Episode 276/500, Total Reward: 10.31\n",
      "Episode 277/500, Total Reward: 15.61\n",
      "Episode 278/500, Total Reward: 6.27\n",
      "Episode 279/500, Total Reward: 7.84\n",
      "Episode 280/500, Total Reward: 4.58\n",
      "Episode 281/500, Total Reward: 7.63\n",
      "Episode 282/500, Total Reward: 12.33\n",
      "Episode 283/500, Total Reward: 8.16\n",
      "Episode 284/500, Total Reward: 11.16\n",
      "Episode 285/500, Total Reward: 9.85\n",
      "Episode 286/500, Total Reward: 3.87\n",
      "Episode 287/500, Total Reward: 13.70\n",
      "Episode 288/500, Total Reward: 4.47\n",
      "Episode 289/500, Total Reward: 8.97\n",
      "Episode 290/500, Total Reward: 9.65\n",
      "Episode 291/500, Total Reward: 7.13\n",
      "Episode 292/500, Total Reward: 1.82\n",
      "Episode 293/500, Total Reward: 0.79\n",
      "Episode 294/500, Total Reward: 2.38\n",
      "Episode 295/500, Total Reward: 11.96\n",
      "Episode 296/500, Total Reward: 6.98\n",
      "Episode 297/500, Total Reward: 10.15\n",
      "Episode 298/500, Total Reward: 7.18\n",
      "Episode 299/500, Total Reward: 9.75\n",
      "Episode 300/500, Total Reward: 8.00\n",
      "Episode 301/500, Total Reward: 9.49\n",
      "Episode 302/500, Total Reward: 7.47\n",
      "Episode 303/500, Total Reward: 10.86\n",
      "Episode 304/500, Total Reward: 14.14\n",
      "Episode 305/500, Total Reward: 5.08\n",
      "Episode 306/500, Total Reward: 2.51\n",
      "Episode 307/500, Total Reward: 5.02\n",
      "Episode 308/500, Total Reward: 6.42\n",
      "Episode 309/500, Total Reward: 22.80\n",
      "Episode 310/500, Total Reward: 2.53\n",
      "Episode 311/500, Total Reward: 7.12\n",
      "Episode 312/500, Total Reward: 8.97\n",
      "Episode 313/500, Total Reward: 8.36\n",
      "Episode 314/500, Total Reward: 5.37\n",
      "Episode 315/500, Total Reward: 8.03\n",
      "Episode 316/500, Total Reward: 5.73\n",
      "Episode 317/500, Total Reward: 3.75\n",
      "Episode 318/500, Total Reward: 4.68\n",
      "Episode 319/500, Total Reward: 2.46\n",
      "Episode 320/500, Total Reward: 5.47\n",
      "Episode 321/500, Total Reward: 7.60\n",
      "Episode 322/500, Total Reward: 2.10\n",
      "Episode 323/500, Total Reward: 3.54\n",
      "Episode 324/500, Total Reward: 0.44\n",
      "Episode 325/500, Total Reward: 4.33\n",
      "Episode 326/500, Total Reward: 5.11\n",
      "Episode 327/500, Total Reward: 7.11\n",
      "Episode 328/500, Total Reward: 13.37\n",
      "Episode 329/500, Total Reward: 3.34\n",
      "Episode 330/500, Total Reward: 9.08\n",
      "Episode 331/500, Total Reward: 14.08\n",
      "Episode 332/500, Total Reward: 14.53\n",
      "Episode 333/500, Total Reward: 8.95\n",
      "Episode 334/500, Total Reward: 4.88\n",
      "Episode 335/500, Total Reward: 3.53\n",
      "Episode 336/500, Total Reward: 8.61\n",
      "Episode 337/500, Total Reward: 14.03\n",
      "Episode 338/500, Total Reward: 11.73\n",
      "Episode 339/500, Total Reward: 2.03\n",
      "Episode 340/500, Total Reward: 5.35\n",
      "Episode 341/500, Total Reward: 9.42\n",
      "Episode 342/500, Total Reward: 8.97\n",
      "Episode 343/500, Total Reward: 0.55\n",
      "Episode 344/500, Total Reward: 9.05\n",
      "Episode 345/500, Total Reward: 4.85\n",
      "Episode 346/500, Total Reward: 6.80\n",
      "Episode 347/500, Total Reward: 12.05\n",
      "Episode 348/500, Total Reward: 7.97\n",
      "Episode 349/500, Total Reward: 9.03\n",
      "Episode 350/500, Total Reward: 10.73\n",
      "Episode 351/500, Total Reward: 18.16\n",
      "Episode 352/500, Total Reward: 3.52\n",
      "Episode 353/500, Total Reward: 6.35\n",
      "Episode 354/500, Total Reward: 15.10\n",
      "Episode 355/500, Total Reward: 10.12\n",
      "Episode 356/500, Total Reward: 7.82\n",
      "Episode 357/500, Total Reward: 5.79\n",
      "Episode 358/500, Total Reward: 3.99\n",
      "Episode 359/500, Total Reward: 6.45\n",
      "Episode 360/500, Total Reward: 9.60\n",
      "Episode 361/500, Total Reward: 17.21\n",
      "Episode 362/500, Total Reward: 16.75\n",
      "Episode 363/500, Total Reward: 2.40\n",
      "Episode 364/500, Total Reward: 16.46\n",
      "Episode 365/500, Total Reward: 3.07\n",
      "Episode 366/500, Total Reward: 10.90\n",
      "Episode 367/500, Total Reward: 6.48\n",
      "Episode 368/500, Total Reward: 2.07\n",
      "Episode 369/500, Total Reward: 4.09\n",
      "Episode 370/500, Total Reward: 4.27\n",
      "Episode 371/500, Total Reward: 8.04\n",
      "Episode 372/500, Total Reward: 4.65\n",
      "Episode 373/500, Total Reward: 19.98\n",
      "Episode 374/500, Total Reward: 14.05\n",
      "Episode 375/500, Total Reward: 10.70\n",
      "Episode 376/500, Total Reward: 10.54\n",
      "Episode 377/500, Total Reward: 12.50\n",
      "Episode 378/500, Total Reward: 14.68\n",
      "Episode 379/500, Total Reward: 9.22\n",
      "Episode 380/500, Total Reward: 8.64\n",
      "Episode 381/500, Total Reward: 7.98\n",
      "Episode 382/500, Total Reward: 15.46\n",
      "Episode 383/500, Total Reward: 0.42\n",
      "Episode 384/500, Total Reward: 4.96\n",
      "Episode 385/500, Total Reward: 7.09\n",
      "Episode 386/500, Total Reward: 4.73\n",
      "Episode 387/500, Total Reward: 6.43\n",
      "Episode 388/500, Total Reward: 1.35\n",
      "Episode 389/500, Total Reward: 7.43\n",
      "Episode 390/500, Total Reward: 5.78\n",
      "Episode 391/500, Total Reward: 9.67\n",
      "Episode 392/500, Total Reward: 9.36\n",
      "Episode 393/500, Total Reward: 11.54\n",
      "Episode 394/500, Total Reward: 15.28\n",
      "Episode 395/500, Total Reward: 12.10\n",
      "Episode 396/500, Total Reward: 18.99\n",
      "Episode 397/500, Total Reward: 9.21\n",
      "Episode 398/500, Total Reward: 1.09\n",
      "Episode 399/500, Total Reward: 11.84\n",
      "Episode 400/500, Total Reward: 10.41\n",
      "Episode 401/500, Total Reward: 11.15\n",
      "Episode 402/500, Total Reward: 9.55\n",
      "Episode 403/500, Total Reward: 7.08\n",
      "Episode 404/500, Total Reward: 21.39\n",
      "Episode 405/500, Total Reward: 10.44\n",
      "Episode 406/500, Total Reward: 10.38\n",
      "Episode 407/500, Total Reward: 6.31\n",
      "Episode 408/500, Total Reward: 2.48\n",
      "Episode 409/500, Total Reward: 4.97\n",
      "Episode 410/500, Total Reward: 10.89\n",
      "Episode 411/500, Total Reward: 15.49\n",
      "Episode 412/500, Total Reward: 6.16\n",
      "Episode 413/500, Total Reward: 10.30\n",
      "Episode 414/500, Total Reward: 7.57\n",
      "Episode 415/500, Total Reward: 12.74\n",
      "Episode 416/500, Total Reward: 15.91\n",
      "Episode 417/500, Total Reward: 9.24\n",
      "Episode 418/500, Total Reward: 4.59\n",
      "Episode 419/500, Total Reward: 6.23\n",
      "Episode 420/500, Total Reward: 4.30\n",
      "Episode 421/500, Total Reward: 8.72\n",
      "Episode 422/500, Total Reward: 8.92\n",
      "Episode 423/500, Total Reward: 8.00\n",
      "Episode 424/500, Total Reward: 13.40\n",
      "Episode 425/500, Total Reward: 7.88\n",
      "Episode 426/500, Total Reward: 10.35\n",
      "Episode 427/500, Total Reward: 8.41\n",
      "Episode 428/500, Total Reward: 12.33\n",
      "Episode 429/500, Total Reward: 11.52\n",
      "Episode 430/500, Total Reward: 7.78\n",
      "Episode 431/500, Total Reward: 11.62\n",
      "Episode 432/500, Total Reward: 10.99\n",
      "Episode 433/500, Total Reward: 9.45\n",
      "Episode 434/500, Total Reward: 6.11\n",
      "Episode 435/500, Total Reward: 8.99\n",
      "Episode 436/500, Total Reward: 16.09\n",
      "Episode 437/500, Total Reward: 16.33\n",
      "Episode 438/500, Total Reward: 9.07\n",
      "Episode 439/500, Total Reward: 5.46\n",
      "Episode 440/500, Total Reward: 5.74\n",
      "Episode 441/500, Total Reward: 7.92\n",
      "Episode 442/500, Total Reward: 7.90\n",
      "Episode 443/500, Total Reward: 10.85\n",
      "Episode 444/500, Total Reward: 9.64\n",
      "Episode 445/500, Total Reward: 7.80\n",
      "Episode 446/500, Total Reward: 5.28\n",
      "Episode 447/500, Total Reward: 7.65\n",
      "Episode 448/500, Total Reward: 4.37\n",
      "Episode 449/500, Total Reward: 14.42\n",
      "Episode 450/500, Total Reward: 10.02\n",
      "Episode 451/500, Total Reward: 10.85\n",
      "Episode 452/500, Total Reward: 3.39\n",
      "Episode 453/500, Total Reward: 19.49\n",
      "Episode 454/500, Total Reward: 14.06\n",
      "Episode 455/500, Total Reward: -0.02\n",
      "Episode 456/500, Total Reward: 9.69\n",
      "Episode 457/500, Total Reward: 13.44\n",
      "Episode 458/500, Total Reward: 8.65\n",
      "Episode 459/500, Total Reward: 16.97\n",
      "Episode 460/500, Total Reward: 4.19\n",
      "Episode 461/500, Total Reward: 13.61\n",
      "Episode 462/500, Total Reward: 3.74\n",
      "Episode 463/500, Total Reward: 14.74\n",
      "Episode 464/500, Total Reward: 11.84\n",
      "Episode 465/500, Total Reward: 17.89\n",
      "Episode 466/500, Total Reward: 2.62\n",
      "Episode 467/500, Total Reward: 9.78\n",
      "Episode 468/500, Total Reward: 2.60\n",
      "Episode 469/500, Total Reward: 5.07\n",
      "Episode 470/500, Total Reward: 9.00\n",
      "Episode 471/500, Total Reward: 12.45\n",
      "Episode 472/500, Total Reward: 7.16\n",
      "Episode 473/500, Total Reward: 7.12\n",
      "Episode 474/500, Total Reward: 6.24\n",
      "Episode 475/500, Total Reward: 9.04\n",
      "Episode 476/500, Total Reward: 7.17\n",
      "Episode 477/500, Total Reward: 8.68\n",
      "Episode 478/500, Total Reward: 7.21\n",
      "Episode 479/500, Total Reward: 1.64\n",
      "Episode 480/500, Total Reward: 14.14\n",
      "Episode 481/500, Total Reward: 6.84\n",
      "Episode 482/500, Total Reward: 15.15\n",
      "Episode 483/500, Total Reward: 5.87\n",
      "Episode 484/500, Total Reward: 5.46\n",
      "Episode 485/500, Total Reward: 12.75\n",
      "Episode 486/500, Total Reward: 5.49\n",
      "Episode 487/500, Total Reward: 13.56\n",
      "Episode 488/500, Total Reward: 7.18\n",
      "Episode 489/500, Total Reward: 12.67\n",
      "Episode 490/500, Total Reward: 7.23\n",
      "Episode 491/500, Total Reward: 16.79\n",
      "Episode 492/500, Total Reward: 7.72\n",
      "Episode 493/500, Total Reward: 5.72\n",
      "Episode 494/500, Total Reward: 6.43\n",
      "Episode 495/500, Total Reward: 11.57\n",
      "Episode 496/500, Total Reward: 11.18\n",
      "Episode 497/500, Total Reward: 2.17\n",
      "Episode 498/500, Total Reward: 11.94\n",
      "Episode 499/500, Total Reward: 10.62\n",
      "Episode 500/500, Total Reward: 10.08\n",
      "DQN model saved!\n",
      "Average Reward: -4.4545\n",
      "Action Distribution: {0: 0.334, 1: 0.322, 2: 0.344}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-4.454542870408306, {0: 0.334, 1: 0.322, 2: 0.344})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Define RL Environment\n",
    "class ResourceScalingEnv:\n",
    "    def __init__(self):\n",
    "        self.state_size = 3  # EC2, RDS, ECS predicted usage\n",
    "        self.action_size = 3  # Scale up, scale down, no action\n",
    "        self.state = np.zeros(self.state_size)\n",
    "        self.reward = 0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.random.rand(self.state_size)  # Start with random usage\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Simulate impact of action\n",
    "        if action == 0:  # Scale Up\n",
    "            self.state += np.random.uniform(0.01, 0.05, self.state_size)\n",
    "            self.reward = -self.state.sum()  # More usage, more cost\n",
    "        elif action == 1:  # Scale Down\n",
    "            self.state -= np.random.uniform(0.01, 0.05, self.state_size)\n",
    "            self.reward = self.state.sum()  # Less cost, but risk of under-scaling\n",
    "        else:  # No Action\n",
    "            self.reward = -abs(self.state.sum() - 0.5)  # Penalty for over/under allocation\n",
    "        \n",
    "        self.state = np.clip(self.state, 0, 1)  # Ensure valid range\n",
    "        return self.state, self.reward\n",
    "\n",
    "# Define Deep Q-Network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Train DQN Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Discount factor\n",
    "        self.epsilon = 1.0  # Exploration-exploitation balance\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = DQN(state_size, action_size)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.choice([0, 1, 2])\n",
    "        state_tensor = torch.FloatTensor(state).float()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.model(state_tensor)\n",
    "        return torch.argmax(action_values).item()\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state in minibatch:\n",
    "            target = reward + self.gamma * torch.max(self.model(torch.FloatTensor(next_state).float())).item()\n",
    "            predicted_target = self.model(torch.FloatTensor(state))[action]\n",
    "            loss = self.criterion(predicted_target, torch.tensor(target).float())\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Main Training Loop\n",
    "def train_rl_agent(episodes=500):\n",
    "    env = ResourceScalingEnv()\n",
    "    agent = DQNAgent(env.state_size, env.action_size)\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        for _ in range(10):  # Simulate 10 steps per episode\n",
    "            action = agent.act(state)\n",
    "            next_state, reward = env.step(action)\n",
    "            agent.remember(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "        agent.replay(32)\n",
    "        print(f\"Episode {episode+1}/{episodes}, Total Reward: {total_reward:.2f}\")\n",
    "    torch.save(agent.model.state_dict(), \"dqn_scaling_model.pth\")\n",
    "    print(\"DQN model saved!\")\n",
    "\n",
    "# Evaluate RL Model\n",
    "def evaluate_rl_agent(episodes=100):\n",
    "    env = ResourceScalingEnv()\n",
    "    agent = DQNAgent(env.state_size, env.action_size)\n",
    "    agent.model.load_state_dict(torch.load(\"dqn_scaling_model.pth\"))\n",
    "    agent.model.eval()\n",
    "    \n",
    "    total_rewards = []\n",
    "    action_counts = {0: 0, 1: 0, 2: 0}\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        for _ in range(10):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward = env.step(action)\n",
    "            total_reward += reward\n",
    "            action_counts[action] += 1\n",
    "            state = next_state\n",
    "        total_rewards.append(total_reward)\n",
    "    \n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    action_distribution = {k: v / sum(action_counts.values()) for k, v in action_counts.items()}\n",
    "    print(f\"Average Reward: {avg_reward:.4f}\")\n",
    "    print(f\"Action Distribution: {action_distribution}\")\n",
    "    return avg_reward, action_distribution\n",
    "\n",
    "# Run training\n",
    "train_rl_agent()\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_rl_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rl_agent(episodes=100):\n",
    "    env = ResourceScalingEnv()\n",
    "    agent = DQNAgent(env.state_size, env.action_size)\n",
    "    agent.model.load_state_dict(torch.load(\"dqn_scaling_model.pth\"))\n",
    "    agent.model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    total_rewards = []\n",
    "    action_counts = {0: 0, 1: 0, 2: 0}  # Track action distribution\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        for _ in range(10):  # Simulate 10 steps per episode\n",
    "            action = agent.act(state)\n",
    "            next_state, reward = env.step(action)\n",
    "\n",
    "            total_reward += reward\n",
    "            action_counts[action] += 1  # Track action usage\n",
    "            state = next_state  # Update state\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "    \n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    action_distribution = {k: v / sum(action_counts.values()) for k, v in action_counts.items()}\n",
    "\n",
    "    print(f\"Average Reward: {avg_reward:.4f}\")\n",
    "    print(f\"Action Distribution: {action_distribution}\")\n",
    "\n",
    "    return avg_reward, action_distribution\n",
    "\n",
    "# Run the test function\n",
    "test_rl_agent()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
